# Default values for helm.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.
rbac:
  # -- Enable bootstraping of RBAC resources
  enabled: true

nameOverride: ""
fullnameOverride: ""

# Plugin Configuration
config:
  # -- Whether to enable querying for IPv6 records
  ipv6: false
  # -- HTTP request timeout
  timeout: 10s
  # -- Timeout to wait on shutdown to allow load balancers detect that we're going away.
  # During this period after the shutdown command the /alive endpoint will reply with HTTP 503.
  # Set to 0s to disable.
  timeoutShutdown: 10s
  # -- Max number of parallel incoming HTTP requests to handle
  concurrency: 1000
  # -- Whether to forward metrics metadata from Prometheus to Cortex
  # Since metadata requests have no timeseries in them - we cannot divide them into tenants
  # So the metadata requests will be sent to the default tenant only, if one is not defined - they will be dropped
  metadata: false
  # -- HTTP error code to return when the request is rejected (backend unavailable, no tenant found, etc.). 429 indicates for most clients that the request was rejected and that it should be retried later.
  httpErrorCode: 429
  # -- Maximum duration to keep outgoing connections alive (to Cortex/Mimir)
  # Useful for resetting L4 load-balancer state
  # Use 0 to keep them indefinitely
  maxConnectionDuration: 0s
  # -- This parameter sets the limit for the count of outgoing concurrent connections to Cortex / Mimir.
  # By default it's 64 and if all of these connections are busy you will get errors when pushing from Prometheus.
  # If your `target` is a DNS name that resolves to several IPs then this will be a per-IP limit.
  maxConnectionsPerHost: 64
  # -- Configure the backend to redirect all the requests to
  backend:
    # -- Where to send the modified requests (Cortex)
    url: http://loki-distributor.cortex.svc:8080/api/v1/push
    # Authentication (optional)
    auth:
      # -- Username
      username: ""
      # -- Password
      password: ""
  # -- Specify which tenants should be selected for this proxy.
  # Tenants not matching the labels are not considered by the controller.
  selector: {}
  # Tenant Properties
  tenant:
    # -- List of labels examined for tenant information. If set takes precedent over `label`
    labels: []
    # -- Optional hard-coded prefix with delimeter for all tenant values.
    # Delimeters allowed for use:
    # https://grafana.com/docs/mimir/latest/configure/about-tenant-ids/
    prefix: ""
    # -- If true will use the tenant ID of the inbound request as the prefix of the new tenant id.
    # Will be automatically suffixed with a `-` character.
    # Example:
    #   Prometheus forwards metrics with `X-Scope-OrgID: Prom-A` set in the inbound request.
    #   This would result in the tenant prefix being set to `Prom-A-`.
    prefixPreferSource: false
    # -- Whether to remove the tenant label from the request
    labelRemove: false
    # -- Set this value to add the evaluated tenant as label on the data set. If empty, no label is added
    tenantLabel: ""
    # -- Whether to set the HTTP header (Header above) with the tenant ID. If false, no header will be set. Useful when you just want to aggregate the tenant as label to the data set.
    setHeader: true
    # -- To which header to add the tenant ID
    header: X-Scope-OrgID
    # -- Which tenant ID to use if the label is missing in any of the timeseries
    # If this is not set or empty then the write request with missing tenant label
    # will be rejected with HTTP code 400
    default: ""
    # -- When no tenant ID is defined via namespace annotations, use the namespace name as tenant ID.
    # -- This has priority over the `default` tenant ID.
    setNamespaceAsDefault: false
    # -- Enable if you want all metrics from Prometheus to be accepted with a 204 HTTP code
    # regardless of the response from Cortex. This can lose metrics if Cortex is
    # throwing rejections.
    acceptAll: false

# Arguments for the controller
args:
  # -- Enable Profiling
  pprof: false
  # -- Log Level
  logLevel: 4
  # -- A list of extra arguments to add to the capsule-argo-addon
  extraArgs: []

# -- Amount of replicas
replicaCount: 1
image:
  # -- Set the image registry
  registry: ghcr.io
  # -- Set the image repository
  repository: peak-scale/observability-tenancy/loki-proxy
  # -- Set the image pull policy.
  pullPolicy: IfNotPresent
  # -- Overrides the image tag whose default is the chart appVersion.
  tag: ""

# -- Configuration for `imagePullSecrets` so that you can use a private images registry.
imagePullSecrets: []

serviceAccount:
  # -- Specifies whether a service account should be created.
  create: true
  # -- Annotations to add to the service account.
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
   # -- The name of the service account to use.
  name: ""

# -- Annotations to add
podAnnotations: {}

# -- Set the securityContext
podSecurityContext:
  seccompProfile:
    type: RuntimeDefault

# -- Set the securityContext for the container
securityContext:
  allowPrivilegeEscalation: false
  capabilities:
    drop:
    - ALL
  readOnlyRootFilesystem: true
  runAsNonRoot: true
  runAsUser: 1000

# -- Configure the liveness probe using Deployment probe spec
livenessProbe:
  httpGet:
    path: /healthz
    port: 10080

# -- Configure the readiness probe using Deployment probe spec
readinessProbe:
  httpGet:
    path: /readyz
    port: 10080

# -- Set the resource requests/limits
resources: {}

# -- Set the priority class name of the Capsule pod
priorityClassName: '' # system-cluster-critical

# -- Set the node selector
nodeSelector: {}

# -- Set list of tolerations
tolerations: []

# -- Set affinity rules
affinity: {}

# -- Set topology spread constraints
topologySpreadConstraints: []

# Pod Disruption Budget
pdb:
  # -- Specifies whether an hpa should be created.
  enabled: false
  # -- The number of pods from that set that must still be available after the eviction
  minAvailable: 1

# HorizontalPodAutoscaler
autoscaling:
  # -- Specifies whether an hpa should be created.
  enabled: false
  # -- Labels to add to the hpa.
  labels: {}
  # -- Annotations to add to the hpa.
  annotations: {}
  # -- Set the minReplicas for hpa.
  minReplicas: 1
  # -- Set the maxReplicas for hpa.
  maxReplicas: 3
  # -- Set the targetCPUUtilizationPercentage for hpa.
  targetCPUUtilizationPercentage: 0
  # -- Set the targetMemoryUtilizationPercentage for hpa.
  targetMemoryUtilizationPercentage: 0
  # -- Custom [metrics-objects](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/#autoscaling-on-multiple-metrics-and-custom-metrics) for capsule-proxy hpa
  metrics: []
  # - type: Pods
  #   pods:
  #     metric:
  #       name: packets-per-second
  #     target:
  #       type: AverageValue
  #       averageValue: 1k
  # -- HPA [behavior](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/)
  behavior: {}
  # scaleDown:
  #   policies:
  #   - type: Pods
  #     value: 4
  #     periodSeconds: 60
  #   - type: Percent
  #     value: 10
  #     periodSeconds: 60


# Monitoring Values
monitoring:
  # -- Enable Monitoring of the Operator
  enabled: false
  # PrometheusRules
  rules:
    # -- Enable deployment of PrometheusRules
    enabled: true
    # -- Install the rules into a different Namespace, as the monitoring stack one (default: the release one)
    namespace: ''
    # -- Assign additional labels
    labels: {}
    # -- Assign additional Annotations
    annotations: {}
    # -- Prometheus Groups for the rule
    groups: []
    # - alert: LokiProxyTooMany500s
    #   expr: 100 * ( sum( timeseries_request_duration_seconds{code=~"5.+"} ) / sum(timeseries_request_duration_seconds) ) > 5
    #   for: 5m
    #   labels:
    #     severity: warning
    #   annotations:
    #     description: Too many 5XXs
    #     summary: More than 5% of all requests returned 5XX, this requires your attention
    # - alert: LokiProxyTooMany400s
    #   expr: 100 * ( sum( timeseries_request_duration_seconds{status=~"4.+"} ) / sum(timeseries_request_duration_seconds) ) > 5
    #   for: 5m
    #   labels:
    #     severity: warning
    #   annotations:
    #     description: Too many 4XXs
    #     summary: More than 5% of all requests returned 4XX, this requires your attention
  # ServiceMonitor
  serviceMonitor:
    # -- Enable ServiceMonitor
    enabled: true
    # -- Install the ServiceMonitor into a different Namespace, as the monitoring stack one (default: the release one)
    namespace: ''
    # -- Assign additional labels according to Prometheus' serviceMonitorSelector matching labels
    labels: {}
    # -- Assign additional Annotations
    annotations: {}
    # -- Change matching labels
    matchLabels: {}
    # -- Prometheus Joblabel
    jobLabel: app.kubernetes.io/name
    # -- Set targetLabels for the serviceMonitor
    targetLabels: []
    serviceAccount:
      # @default -- `capsule-proxy`
      name: ""
      # @default -- `.Release.Namespace`
      namespace: ""
    endpoint:
      # -- Set the scrape interval for the endpoint of the serviceMonitor
      interval: "15s"
      # -- Set the scrape timeout for the endpoint of the serviceMonitor
      scrapeTimeout: ""
      # -- Set metricRelabelings for the endpoint of the serviceMonitor
      metricRelabelings: []
      # -- Set relabelings for the endpoint of the serviceMonitor
      relabelings: []
